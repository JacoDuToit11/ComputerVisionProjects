{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPb3Kx47a9WCjhphM/sOdB+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JacoDuToit11/ComputerVisionProjects/blob/main/PetEmotionClassification/PetEmotionClassifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "bB3xDEz6rbfv"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import transforms\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision.models import resnet18"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Zt4kk-lweef",
        "outputId": "d78a4456-91f5-48d9-ff9a-9b49e903369c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "happy_folder = \"/content/drive/MyDrive/PetEmotionData/happy\"\n",
        "sad_folder = \"/content/drive/MyDrive/PetEmotionData/Sad\"\n",
        "angry_folder = \"/content/drive/MyDrive/PetEmotionData/Angry\"\n",
        "\n",
        "# Function to load and preprocess images\n",
        "def load_images_from_folder(folder):\n",
        "    images = []\n",
        "    for filename in os.listdir(folder):\n",
        "        img = cv2.imread(os.path.join(folder, filename))\n",
        "        if img is not None:\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "            img = cv2.resize(img, (48, 48))  # Resize to a fixed size for the model\n",
        "            images.append(img)\n",
        "    return images\n",
        "\n",
        "# Load images and labels for each emotion\n",
        "happy_images = load_images_from_folder(happy_folder)\n",
        "sad_images = load_images_from_folder(sad_folder)\n",
        "angry_images = load_images_from_folder(angry_folder)\n",
        "\n",
        "happy_labels = [0] * len(happy_images)\n",
        "sad_labels = [1] * len(sad_images)\n",
        "angry_labels = [2] * len(angry_images)\n",
        "\n",
        "# Concatenate images and labels\n",
        "X = np.array(happy_images + sad_images + angry_images)\n",
        "y = np.array(happy_labels + sad_labels + angry_labels)\n",
        "\n",
        "# Normalize pixel values to range [0, 1]\n",
        "X = X.astype('float32') / 255.0\n",
        "\n",
        "# One-hot encode the labels\n",
        "one_hot_y = np.eye(np.max(y) + 1)[y]\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, one_hot_y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "y5wxVu9rwfUx"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, X, y, transform=None):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image = self.X[index]\n",
        "        label = self.y[index]\n",
        "\n",
        "        # Apply transformations if provided\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),  # Convert image to PyTorch tensor\n",
        "    # Add more transformations if needed (e.g., normalization)\n",
        "])\n",
        "\n",
        "train_dataset = CustomDataset(X_train, y_train, transform=transform)\n",
        "test_dataset = CustomDataset(X_test, y_test, transform=transform)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "sl4En1Y50gIo"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Basic CNN Classifier\n",
        "class CNNClassifier(nn.Module):\n",
        "  def __init__(self, num_classes):\n",
        "    super(CNNClassifier, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
        "    self.fc1 = nn.Linear(32 * 12 * 12, 256)\n",
        "    self.fc2 = nn.Linear(256, num_classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.pool(x)\n",
        "    x = self.conv2(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.pool(x)\n",
        "    x = x.view(-1, 32 * 12 * 12)\n",
        "    x = self.fc1(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.fc2(x)\n",
        "    return x\n",
        "\n",
        "num_classes = len(y_train[0])  # Assuming y_train is one-hot encoded\n",
        "model = CNNClassifier(num_classes)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 20\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for images, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, torch.argmax(labels, dim=1))  # Assuming labels are one-hot encoded\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Print training loss for each epoch\n",
        "    print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {loss.item()}')\n",
        "\n",
        "# Evaluation on the test set\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == torch.argmax(labels, dim=1)).sum().item()\n",
        "\n",
        "accuracy = correct / total\n",
        "print(f'Test Accuracy: {accuracy * 100:.2f}%')"
      ],
      "metadata": {
        "id": "tUcqsRTH1vyp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "179f15b5-e8b0-4e98-fd9b-c776cf13e215"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20, Loss: 1.096474528312683\n",
            "Epoch 2/20, Loss: 1.0862946510314941\n",
            "Epoch 3/20, Loss: 1.0836280584335327\n",
            "Epoch 4/20, Loss: 1.165968418121338\n",
            "Epoch 5/20, Loss: 0.9758689403533936\n",
            "Epoch 6/20, Loss: 0.9500083327293396\n",
            "Epoch 7/20, Loss: 0.740239143371582\n",
            "Epoch 8/20, Loss: 0.772416353225708\n",
            "Epoch 9/20, Loss: 0.8514420986175537\n",
            "Epoch 10/20, Loss: 0.3979153335094452\n",
            "Epoch 11/20, Loss: 0.5576593279838562\n",
            "Epoch 12/20, Loss: 0.3101760447025299\n",
            "Epoch 13/20, Loss: 0.3495209217071533\n",
            "Epoch 14/20, Loss: 0.17198903858661652\n",
            "Epoch 15/20, Loss: 0.17528913915157318\n",
            "Epoch 16/20, Loss: 0.10109645128250122\n",
            "Epoch 17/20, Loss: 0.13967536389827728\n",
            "Epoch 18/20, Loss: 0.11909573525190353\n",
            "Epoch 19/20, Loss: 0.07473278790712357\n",
            "Epoch 20/20, Loss: 0.09218872338533401\n",
            "Test Accuracy: 52.67%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "happy_folder = \"/content/drive/MyDrive/PetEmotionData/happy\"\n",
        "sad_folder = \"/content/drive/MyDrive/PetEmotionData/Sad\"\n",
        "angry_folder = \"/content/drive/MyDrive/PetEmotionData/Angry\"\n",
        "\n",
        "# Function to load and preprocess images\n",
        "def load_images_from_folder(folder):\n",
        "    images = []\n",
        "    for filename in os.listdir(folder):\n",
        "        img = cv2.imread(os.path.join(folder, filename))\n",
        "        if img is not None:\n",
        "            img = cv2.resize(img, (224, 224))  # Resize to a fixed size for the model\n",
        "            images.append(img)\n",
        "    return images\n",
        "\n",
        "# Load images and labels for each emotion\n",
        "happy_images = load_images_from_folder(happy_folder)\n",
        "sad_images = load_images_from_folder(sad_folder)\n",
        "angry_images = load_images_from_folder(angry_folder)\n",
        "\n",
        "happy_labels = [0] * len(happy_images)\n",
        "sad_labels = [1] * len(sad_images)\n",
        "angry_labels = [2] * len(angry_images)\n",
        "\n",
        "# Concatenate images and labels\n",
        "X = np.array(happy_images + sad_images + angry_images)\n",
        "y = np.array(happy_labels + sad_labels + angry_labels)\n",
        "\n",
        "# Normalize pixel values to range [0, 1]\n",
        "X = X.astype('float32') / 255.0\n",
        "\n",
        "# One-hot encode the labels\n",
        "one_hot_y = np.eye(np.max(y) + 1)[y]\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, one_hot_y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "WpU8MGG1AYO0"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, X, y, transform=None):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image = self.X[index]\n",
        "        label = self.y[index]\n",
        "\n",
        "        # Apply transformations if provided\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),  # Convert image to PyTorch tensor\n",
        "    # Add more transformations if needed (e.g., normalization)\n",
        "])\n",
        "\n",
        "train_dataset = CustomDataset(X_train, y_train, transform=transform)\n",
        "test_dataset = CustomDataset(X_test, y_test, transform=transform)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "Jk10CHiLAh8o"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fine-tune pre-trained CNN model.\n",
        "class FineTunedResNet18(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(FineTunedResNet18, self).__init__()\n",
        "        # Load pre-trained ResNet18 model\n",
        "        resnet = resnet18(pretrained=True)\n",
        "\n",
        "        # Remove the last fully connected layer and replace it with a new one\n",
        "        self.features = nn.Sequential(*list(resnet.children())[:-1])\n",
        "        self.fc = nn.Linear(resnet.fc.in_features, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "num_classes = len(y_train[0])\n",
        "model = FineTunedResNet18(num_classes)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 20\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for images, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, torch.argmax(labels, dim=1))  # Assuming labels are one-hot encoded\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Print training loss for each epoch\n",
        "    print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {loss.item()}')\n",
        "\n",
        "# Evaluation on the test set\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == torch.argmax(labels, dim=1)).sum().item()\n",
        "\n",
        "accuracy = correct / total\n",
        "print(f'Test Accuracy: {accuracy * 100:.2f}%')"
      ],
      "metadata": {
        "id": "exBxK9Qf7Kkl",
        "outputId": "6721357e-6eeb-4891-95cb-5f62033e4527",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20, Loss: 0.8689529299736023\n",
            "Epoch 2/20, Loss: 0.5605757832527161\n",
            "Epoch 3/20, Loss: 0.36467456817626953\n",
            "Epoch 4/20, Loss: 0.6091190576553345\n",
            "Epoch 5/20, Loss: 0.17594243586063385\n",
            "Epoch 6/20, Loss: 0.08836078643798828\n",
            "Epoch 7/20, Loss: 0.09981609135866165\n",
            "Epoch 8/20, Loss: 0.14092124998569489\n",
            "Epoch 9/20, Loss: 0.01220651250332594\n",
            "Epoch 10/20, Loss: 0.014042079448699951\n",
            "Epoch 11/20, Loss: 0.14129690825939178\n",
            "Epoch 12/20, Loss: 0.18214060366153717\n",
            "Epoch 13/20, Loss: 0.1035454198718071\n",
            "Epoch 14/20, Loss: 0.029728613793849945\n",
            "Epoch 15/20, Loss: 0.16873453557491302\n",
            "Epoch 16/20, Loss: 0.09084930270910263\n",
            "Epoch 17/20, Loss: 0.06927654147148132\n",
            "Epoch 18/20, Loss: 0.07205302268266678\n",
            "Epoch 19/20, Loss: 0.015043962746858597\n",
            "Epoch 20/20, Loss: 0.11300741881132126\n",
            "Test Accuracy: 78.67%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SAS6QsWQ_Ff-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}